<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2019%2F04%2F12%2FLinux%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Linux基础]]></content>
  </entry>
  <entry>
    <title><![CDATA[准确率（Accuracy）、精确度（Precision）、召回率（Recall）、F值（F-Measure）、RoC曲线、PR曲线]]></title>
    <url>%2F2019%2F03%2F31%2F%E7%B2%BE%E7%A1%AE%E5%BA%A6%EF%BC%88Precision%EF%BC%89%E3%80%81%E5%8F%AC%E5%9B%9E%E7%8E%87%EF%BC%88Recall%EF%BC%89%E3%80%81F%E5%80%BC%EF%BC%88F-Measure%EF%BC%89%2F</url>
    <content type="text"><![CDATA[准确率（Accuracy）、精确度（Precision）、召回率（Recall）、F值（F-Measure）、RoC曲线、PR曲线1、TP、FP、TN、FN True Positives，TP：预测为正样本，实际也为正样本的特征数 False Positives，FP：预测为正样本，实际为负样本的特征数 True Negatives，TN：预测为负样本，实际也为负样本的特征数 False Negatives，FN：预测为负样本，实际为正样本的特征数 2、准确率（Accuracy）​ 准确率（Accuracy）是模型预测正例、反例对的数量所占总样本数的比例 A = \frac{TP + TN}{TP + FP +TN + FN}亦即： 准确率 = \frac{预测对的数量}{总样本数量}3、精确度（Precision）​ 精确度（Precision）是针对我们的预测结果而言的，它表示的是预测为正的样本中有多少是真正的正样本。 预测为正有两种可能： 把样本正类预测为正类（TP） 把样本负类预测为正类（FP） P = \frac{TP}{TP + FP}4、召回率（Recall）​ 召回率（Recall）是针对原来的样本而言的，它表示样本中的正例有多少被预测正确了 预测有两种可能： 把样本正类预测成正类（TP） 把样本正类预测为负类（FN） R = \frac{TP}{TP + FN}5、F-SCORE​ 有些时候单一的精确度（Precision）和召回率（Recall）高并不能很好的反映模型的真实性能。我们一般希望Precision和Recall尽可能都高。 所以F-SCORE(或称F-Measure): F = \frac{P * R * 2}{P + R}or \frac{2}{F} = \frac{1}{P} + \frac{1}{Q}6、例子​ 原始样本：60个是好瓜，40个是坏瓜，总数：100。 ​ 你训练了一个选西瓜的模型。你的模型挑选出85个瓜。里边真实标记有50个好瓜，35个坏瓜。 TP（将好瓜预测成好瓜）：40 FP（将坏瓜预测成好瓜）：15 TN（将坏瓜预测成坏瓜）：20 FN（将好瓜预测成坏瓜）：10 A = \frac{TP+TN}{TP+FP+TN+FN} = \frac{40+20}{85}= 70\% P =\frac{TP}{TP+FP} =\frac{40}{40 + 15} = 72.7272\% R = \frac{TP}{TP+FN}=\frac{40}{40 + 10} = 50\% F = \frac{P * R * 2}{P + R} = \frac{0.7272*0.5*2}{0.7272+0.5} = 59.25\%看一张图： 7、灵敏度(true positive rate ,TPR)和特异度(false positive rate, FPR)​ 灵敏度(true positive rate ,TPR)，它是所有实际正例中，正确识别的正例比例，它和召回率的表达式没有区别。 TPR = \frac{TP}{TP+FN}​ 特异度(false positive rate, FPR)，它是实际负例中，错误得识别为正例的负例比例。 FPR = \frac{FP}{FP+FN}8、RoC曲线和PR曲线​ RoC曲线：以TPR为**y轴，以FPR为x轴**。 ​ 从FPR和TPR的定义可以理解，TPR越高，FPR越小，我们的模型和算法就越高效。也就是画出来的RoC曲线越靠近左上越好。从几何的角度讲，RoC曲线下方的面积越大越大，则模型越优。所以有时候我们用RoC曲线下的面积，即AUC（Area Under Curve）值来作为算法和模型好坏的标准。 PR曲线：以Precision为y轴，以Recall为x轴 ​ 仍然从精确率和召回率的定义可以理解，精确率越高，召回率越高，我们的模型和算法就越高效。也就是画出来的PR曲线越靠近右上越好。如上图右图所示。 使用RoC曲线和PR曲线，我们就能很方便的评估我们的模型的分类能力的优劣了。 Reference： [精确率与召回率，RoC曲线与PR曲线] 如何解释召回率与准确率？ 推荐系统评测指标—准确率(Precision)、召回率(Recall)、F值(F-Measure)]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>性能评估</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[维数灾难与过拟合]]></title>
    <url>%2F2019%2F03%2F31%2F%E7%BB%B4%E6%95%B0%E7%81%BE%E9%9A%BE%E4%B8%8E%E8%BF%87%E6%8B%9F%E5%90%88%2F</url>
    <content type="text"><![CDATA[维数灾难与过拟合Reference: 分类问题中的维数灾难与过拟合]]></content>
      <categories>
        <category>机器学习</category>
        <category>领域知识</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>机器学习领域知识</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Hexo下LaTex无法显示的问题]]></title>
    <url>%2F2019%2F03%2F31%2F%E8%A7%A3%E5%86%B3Hexo%E4%B8%8BLaTex%E6%97%A0%E6%B3%95%E6%98%BE%E7%A4%BA%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[解决Hexo下LaTex无法显示的问题配置信息安装Mathjax插件1npm install hexo-math --save 更换Hexo的markdown渲染引擎，[hexo-renderer-kramed][1]引擎是在默认的渲染引擎[hexo-renderer-marked][2]的基础上修改了一些bug，两者比较接近，也比较轻量级。 12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save 更改配置文件​ 在主题配置文件_config.yml中(theme\next_config.yml)修改配置： 123456math: enable: true per_page: true engine: mathjax mathjax: cdn: //cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML 解决语义冲突由于LaTeX与markdown语法有语义冲突，在markdown中，斜体和加粗可以用或者_表示，在这里我们修改变量，将_用于LaTeX，而使用表示markdown中的斜体和加粗。 在博客根目录下，进入node_modules\kramed\lib\rules\inline.js，把第11行的escape变量的值做相应的修改： 12//escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,escape: /^\\([`*\[\]()#$+\-.!_&gt;])/, 12// em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, Reference: hexo下LaTeX无法显示的解决方案 Hexo中的LaTex公式渲染问题]]></content>
      <categories>
        <category>Hexo</category>
        <category>LaTex</category>
      </categories>
      <tags>
        <tag>LaTex</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown简要语法]]></title>
    <url>%2F2019%2F03%2F29%2FMarkdown%E7%AE%80%E8%A6%81%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Markdown简要用法粗斜体代码：123*斜体***粗体*****粗斜体*** 显示效果： 斜体 粗体 粗斜体 标题代码：123456# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 显示效果： 一级标题 二级标题 三级标题 四级标题 五级标题 六级标题注意:#号与标题间有空格 分隔符说明：一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。 代码：1234---- - - **** * * 显示效果(效果都一样)： 超链接行内式代码：1[威威的博客]（https://ailvv.github.io） 显示效果： 威威的博客 参考式代码：12[威威的博客][xx][xx]: https://ailvv.github.io（该语句可放在文章尾部,xx为数字） 显示效果： 威威的博客 简短的自动链接形式说明：Markdown 支持以比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用&lt;&gt;包起来， Markdown 就会自动把它转成链接。 代码：12&lt;http://ailvv.github.io&gt;&lt;iy1573147@163.c0m&gt; 显示效果： http://ailvv.github.io &#105;&#121;&#x31;&#53;&#x37;&#51;&#49;&#52;&#x37;&#x40;&#x31;&#x36;&#51;&#46;&#x63;&#x30;&#109; 列表无序列表说明：使用 *，+，- 表示无序列表。 代码：123456* 无序列表项1* 无序列表项2+ 无序列表项1+ 无序列表项2- 无序列表项1- 无序列表项2 显示效果： 无序列表项1 无序列表项2 无序列表项1 无序列表项2 无序列表项1 无序列表项2 有序列表有序列表则使用数字接着一个英文句点。 代码：1231. 有序列表项 一2. 有序列表项 二3. 有序列表项 三 显示效果： 有序列表项 一 有序列表项 二 有序列表项 三 定义型列表定义型列表由名词和解释组成。一行写上定义，紧跟一行写上解释。解释的写法:紧跟一个缩进(Tab) 代码：1234Markdown: 轻量级文本标记语言，可以转换成html，pdf等格式（左侧有一个可见的冒号和四个不可见的空格）代码块: 这是代码块的定义 显示效果：Markdown: 轻量级文本标记语言，可以转换成html，pdf等格式（左侧有一个可见的冒号和四个不可见的空格 代码块: 这是代码块的定义 列表缩进说明：列表项目标记通常是放在最左边，但也可以缩进，最多 3 个空格，项目标记后面则一定要接着至少一个空格或制表符。 代码：12* 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。* 那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 显示效果： 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 那河畔的金柳， 是夕阳中的新娘； 波光里的艳影， 在我的心头荡漾。 引用说明：引用需要在被引用的文本前加上&gt;符号。 普通引用代码：123&gt;hahaha&gt;yyyyyyy&gt;yeyeyeye 显示效果： hahahayyyyyyyyeyeyeye 引用的多层嵌套代码：123&gt;hahaha&gt;&gt;yyyyyyy&gt;&gt;&gt;yeyeyeye 显示效果： hahaha yyyyyyy yeyeyeye 图片说明：图片的创建方式与超链接相似，和超链接一样，有两种写法，即行内式和参考式写法。语法中: Alt：当图片因某些原因不能显示，就用Alt文字来代替图片 Title：鼠标悬停与图片上时出现的文字 Alt 和 Title 都不是必须的，可省略。 行内式说明： ![图片Alt](图片地址 “图片Title”) 代码：1![美丽天空](https://wx1.sinaimg.cn/mw690/006CCgKCgy1g0uqgq5mmxj31400u0wj2.jpg &quot;美丽天空&quot;) 显示效果： 参考式说明：在文档要插入图片的地方写 ![图片Alt][标记]在文档的最后写上[标记]:图片地址 “Title” 代码：123![美丽天空][sky][sky]:https://wx1.sinaimg.cn/mw690/006CCgKCgy1g0uqgq5mmxj31400u0wj2.jpg &quot;美丽天空&quot; 显示效果： 注脚说明：在需要添加注脚的文字后加上脚注名字注脚名字,称为加注。 然后在文本的任意位置(一般在最后)添加脚注，脚注前必须有对应的脚注名字。 注意：经测试注脚与注脚之间必须空一行，不然会失效。成功后会发现，即使你没有把注脚写在文末，经Markdown转换后，也会自动归类到文章的最后。 代码：12Markdown[^1]支持以比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用&lt;&gt;包起来，Markdown就会自动把它转成链接。[^1]:Markdown是一种纯文本标记语言 显示效果：Markdown1支持以比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用&lt;&gt;包起来，Markdown就会自动把它转成链接。 LaTeX 公式$表示行内公式：代码：1质能守恒方程可以用一个很简洁的方程式 $$E=mc^2$$ 来表达。 显示效果：质能守恒方程可以用一个很简洁的方程式 E=mc^2 来表达。 $表示整行公式：代码：123456789$$sum_&#123;i=1&#125;^n a_i=0$$$$f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2$$$$sum^&#123;j-1&#125;_&#123;k=0&#125;&#123;\widehat&#123;\gamma&#125;_&#123;kj&#125; z_k&#125;$$ 显示效果： sum_{i=1}^n a_i=0 f(x_1,x_x,\ldots,x_n) = x_1^2 + x_2^2 + \cdots + x_n^2 sum^{j-1}_{k=0}{\widehat{\gamma}_{kj} z_k} 注意：若选择Typora进行编辑博文，可选定文章部分内容后再选定左上角段落中的公式块即可生成公式 *更多公式使用方法可访问MathJax或数学公式 Hexo 默认是不支持LaTeX公式语法的，需要添加支持插件，可参考 hexo-math解决方案1 或 hexo-math解决方案2 流程图操作模块语法 start：开始 end:结束 opration:普通操作块 condition:判断块 subroutine:子任务块 inputoutput:输入输出块 代码：&#x60;&#x60;&#x60;flowst=&gt;start: 开始e=&gt;end: 结束op=&gt;operation: 操作sub=&gt;subroutine: 子程序cond=&gt;condition: 是或者不是?io=&gt;inputoutput: 输出st(right)-&gt;op-&gt;condcond(yes)-&gt;io(right)-&gt;econd(no)-&gt;sub(right)-&gt;op&#x60;&#x60;&#x60; 显示效果：123456789st=&gt;start: 开始e=&gt;end: 结束op=&gt;operation: 操作sub=&gt;subroutine: 子程序cond=&gt;condition: 是或者不是?io=&gt;inputoutput: 输出st(right)-&gt;op-&gt;condcond(yes)-&gt;io(right)-&gt;econd(no)-&gt;sub(right)-&gt;op 注意：Hexo 默认是不支持流程图的 Markdown 语法的，需要添加支持：npm install —save hexo-filter-flowchart 表格说明： 绘制表格格式如下，| 控制分列，- 控制分行，: 控制对齐方式。 :——为居左 :——:或——-为居中 ——:为居右 代码：12345| Item | Value | Qty || :------- | --------: | :---: || Computer | 1600 USD | 5 || Phone | 12 USD | 12 || Pipe | 1 USD | 234 | 显示效果： Item Value Qty Computer 1600 USD 5 Phone 12 USD 12 Pipe 1 USD 234 代码说明： 代码分为行内代码和代码块 行内代码使用 &#x60;代码&#x60;标识，可嵌入文字中 代码块使用4个空格或&#x60;&#x60;&#x60;标识 注意： 缩进式代码插入前方须有空行 行内代码：说明：用&#x60;囊括内容 显示效果： scanf() 代码块：说明：用&#x60;&#x60;&#x60;囊括内容。 代码：&#x60;&#x60;&#x60; include int main(void) { printf(“Hello world\n”); }&#x60;&#x60;&#x60; 显示效果:12345include &lt;stdio.h&gt;int main(void)&#123; printf(&quot;Hello world\n&quot;);&#125; 缩进式代码块：代码：&nbsp;&nbsp;&nbsp;&nbsp;include &nbsp;&nbsp;&nbsp;&nbsp;int main(void)&nbsp;&nbsp;&nbsp;&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;printf(“Hello world\n”);&nbsp;&nbsp;&nbsp;&nbsp;} 显示效果：include &lt;stdio.h&gt; int main(void) { printf(&quot;Hello world\n&quot;); } 注意：缩进 4 个空格或是 1 个制表符再写代码，一个代码区块会一直持续到没有缩进的那一行（或是文件结尾） HTML 原始码插入:说明：在代码区块里面， &amp; 、 &lt; 和 &gt; 会自动转成 HTML 实体，这样的方式让你非常容易使用 Markdown 插入范例用的 HTML 原始码，只需要复制贴上，剩下的 Markdown 都会帮你处理，例如： 代码：123456789101112131415&#123;% raw %&#125; &lt;table&gt; &lt;tr&gt; &lt;th rowspan=&quot;2&quot;&gt;值班人员&lt;/th&gt; &lt;th&gt;星期一&lt;/th&gt; &lt;th&gt;星期二&lt;/th&gt; &lt;th&gt;星期三&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;李强&lt;/td&gt; &lt;td&gt;张明&lt;/td&gt; &lt;td&gt;王平&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&#123;% endraw %&#125; 显示效果： 值班人员 星期一 星期二 星期三 李强 张明 王平 工具推荐 在线编辑器 Evernote的失踪Markdown编辑器 Cmd Markdown 编辑阅读器 本地编辑器 Typora 感谢 距离 darryrzhong 1. Markdown是一种纯文本标记语言 &#8617;]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>技巧</tag>
        <tag>经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkDown使用教程]]></title>
    <url>%2F2019%2F03%2F26%2FMarkDown%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[MarkDown使用教程介绍Markdown是一种轻量级标记语言，创始人为约翰·格鲁伯（英语：John Gruber）。它允许人们“使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML（或者HTML）文档”。[4]这种语言吸收了很多在电子邮件中已有的纯文本标记的特性。 由于Markdown的轻量化、易读易写特性，并且对于图片，图表、数学式都有支持，当前许多网站都广泛使用 Markdown 来撰写帮助文档或是用于论坛上发表消息。例如：GitHub、reddit、Diaspora、Stack Exchange、OpenStreetMap 、SourceForge等。甚至Markdown能被使用来撰写电子书。 MarkDown基础语法Reference: MarkDown基础语法 请结合下边的在线编辑器实际写一下，并且查看效果 MarkDown在线编辑阅读器Cmd Markdown 编辑阅读器 MarkDown本地编辑器推荐：Typora (windows) 12 款 Markdown 写作工具推荐]]></content>
      <categories>
        <category>MarkDown</category>
        <category>教程</category>
      </categories>
      <tags>
        <tag>MarkDown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强化学习方法汇总]]></title>
    <url>%2F2019%2F03%2F26%2F%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[强化学习方法汇总​ 是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。其灵感来源于心理学中的行为主义理论，即有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能获得最大利益的习惯性行为。 Reference: 强化学习- 维基百科 不同的划分方式一、不理解环境(Model-Free RL) 和理解环境（Model-Based RL)不理解环境(Model-Free RL) ：​ 直接对环境作出动作，而后接收来自于环境的反馈，对于周围的环境是不理解的，没有概念的，作出动作后只能等待现实的反馈，是否这个动作的反馈会造成好的还是坏的结果，它也是没有概念的、不知道的。 例如：我们在现实世界投放一颗氢弹，然后我们成功把自己玩死了，这是一个很坏的结果，但我们事先对此没有概念，不知道做出这个“投放氢弹”会发生什么，我们只能去尝试一下，然后Die。 方法： Q learning Sarsa Policy Gradients learning 理解环境（Model-Based RL):​ 1、机器人会通过过往的经验，先理解真实世界是怎样的 ​ 2、建立一个模型来模拟现实世界的反馈(建立一个模拟现实) ​ 3、既可以在现实世界中作出动作，也可以在模拟世界中作出动作 这样就没必要去炸真实世界，连自己也炸死了，他可以像玩游戏一样炸炸游戏里的世界，也保住了自己的小命 进一步说明： ​ 基于Model-Based RL的机器人能通过想象来预判断接下来将要发生的所有情况。然后选择这些想象情况中最好的那种。并依据这种情况来采取下一步的策略。 方法： ​ 1、先在Model-Free RL的基础上添加了一层对于现实世界的建模(一个虚拟的世界) ​ 2、然后在这个模拟世界里进行Model-Free RL ( Q learning、Sarsa、Policy Gradients) 二、基于概率(Policy-Based RL) 和基于价值（Value-Based RL)基于概率(Policy-Based RL) :​ 机器人能通过感官分析所处的环境，直接输出下一步要采取的各种动作的概率，然后根据概率采取行动，所以每种动作都有可能被选中， 只是可能性不同，即使是大概率的动作也不一定会选到。 方法： Policy Gradients learning …. 基于价值（Value-Based RL):​ 在当前这一步，输出所有可能采取的动作(不连续的动作)的价值，我们会根据最高价值来选着动作，这种决策十分确定，只选取价值最高的 方法： Q learning Sarsa …. 基于概率与价值的结合创造了一种更好的方法： Actor-Critic ( 1、Actor ：基于概率做出一个动作 2、Critic 会对做出的动作给出动作的价值，这样就在原有的 policy gradients 上加速了学习过程) 对于连续动作： ​ Value-Based是无能为力的 ( 为什么会说无能为力？？？) ​ Policy-Based能用一个概率分布在连续动作中选取特定动作，是Policy-Based的优点之一 三、回合更新(Monte-Carlo update RL) 和单步更新（Temporal-Difference update)想象强化学习就是在玩游戏, 游戏回合有开始和结束 回合更新(Monte-Carlo update RL) ：​ 指的是游戏开始后, 我们要等待游戏结束, 然后再总结这一回合中的所有转折点, 再更新我们的行为准则 方法： Monte-carlo learning 基础版的Policy learning …. 单步更新（Temporal-Difference update)：​ 在游戏进行中每一步都在更新, 不用等待游戏的结束, 这样我们就能边玩边学习了 方法： Q learning Sarsa 升级版Policy Gradients learning … 现在大多数学习都是Temporal-Difference update （因为有的强化学习问题并不属于回合问题，且单步更新训练速度快） 四、在线学习(On-Policy) 和离线学习（Off-Policy)在线学习(On-Policy) :​ 指必须本人在场, 并且一定是本人边玩边学习 方法： Sarsa Sarsa lambda ( 优化Sarsa算法) 离线学习（Off-Policy):特点： 可以选择自己玩 也可以选择看着别人玩，通过看别人玩，来学习别人的行为准则 同样是从过往的经验中学习, 但是这些过往的经历没必要是自己的经历, 任何人的经历都能被学习 或者我也不必要边玩边学习, 我可以白天先存储下来玩耍时的记忆, 然后晚上通过离线学习来学习白天的记忆 方法： Q learning Deep-Q-Network (更加强大的算法，可以让计算机学会玩电动) Reference: 强化学习方法汇总 (Reinforcement Learning)]]></content>
      <categories>
        <category>机器学习</category>
        <category>神经网络</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习、深度学习入门教程]]></title>
    <url>%2F2019%2F03%2F26%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%81%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[教程推荐介绍取自了解机器学习方法 (*可跳) 1.1 机器学习 (Machine Learning) 2.1 科普: 人工神经网络 VS 生物神经网络 2.2 神经网络 (Neural Network) 视频莫凡Python-机器学习（强烈推荐！！！） （强烈推荐！！！通俗易懂，能建立对于机器学习的大致认知，能对大致算法、应用有所了解，不在惧怕 缺点：理论方面不够深入，有志以后进行机器学习相关工作的可以阅读书籍或论文补足理论） 推荐学习顺序： 在机器学习前 - (零基础) Python基础语法 了解数据结构 (Numpy &amp; Pandas) 学会展示数据 (Matplotlib) 了解机器学习方法 (*可跳) 神经网络 Tensorflow (Google开发, 社区大) PyTorch (Facebook开发, 方便debug) Keras (类似Tensorflow, 推荐直接学Tensorflow) Theano (类似Tensorflow, 推荐直接学Tensorflow) 有监督/无监督/半监督/降维多功能包 (Sklearn) 机器人无师自通 (强化学习) 使用进化论的机器学习 (进化算法) 效率工具 代码管理维护 (Git) 远程/云端计算 (Linux基础) 网页爬虫 实战 从头做一个机器人手臂 从头做一个汽车状态分类器 吴恩达网易公开课-深度学习 （英语，但有中文字幕，缺点：缺少了一些课后练习，可以搜索引擎搜索 吴恩达深度学习 课后练习） 书籍1、深度学习 《动手学深度学习》 推荐！！！ 理论与实践并重, 有Kaggle(请看下边的介绍)的练习， 美中不足的是使用的是Mxnet框架，而不是TensorFlow 内容和结构： 本书内容大体可以分为3个部分： 第一部分（第1章至第3章）涵盖预备工作和基础知识。第1章介绍深度学习的背景。第2章提供动手学深度学习所需要的预备知识，例如，如何获取并运行本书中的代码。第3章包括深度学习最基础的概念和技术，如多层感知机和模型正则化。如果读者时间有限，并且只想了解深度学习最基础的概念和技术，那么只需阅读第一部分。 第二部分（第4章至第6章）关注现代深度学习技术。第4章描述深度学习计算的各个重要组成部分，并为实现后续更复杂的模型打下基础。第5章解释近年来令深度学习在计算机视觉领域大获成功的卷积神经网络。第6章阐述近年来常用于处理序列数据的循环神经网络。阅读第二部分有助于掌握现代深度学习技术。 第三部分（第7章至第10章）讨论计算性能和应用。第7章评价各种用来训练深度学习模型的优化算法。第8章检验影响深度学习计算性能的几个重要因素。第9章和第10章分别列举深度学习在计算机视觉和自然语言处理中的重要应用。这部分内容读者可根据兴趣选择阅读。 《神经⽹络与深度学习Neural Networks and Deep Learning》 （讲神经网络的，推荐全看！！！）（美）Michael Nielsen 著Xiaohu Zhu 译Freeman Zhang （内含有反向传播算法的证明，这算法真的很重要） 《解析卷积神经网络(深度学习实践手册)》 （讲卷积神经网络（CNN）的，可以先看《动手学深度学习》的卷积神经网络） 2、机器学习PS：需要高等数学（积分、求导、求梯度、求极值）、线性代数（基本矩阵运算、矩阵求导）、概率论（随机变量、分布、多维随机变量极其分布、期望、贝叶斯公式、极大似然估计），可以先看看书里的大致知识，看不懂再回去补充、回忆 ​ 《机器学习》 周志华 ​ 《统计学习方法》 李航 这两本可以对照着看，如果哪一本难以理解就看另一本或者结合网上的博客 推荐阅读：线性模型（线性回归、对率回归、LDA）、决策树（多变量决策树了解一下即可）、支持向量机、贝叶斯分类(朴素贝叶斯、半朴素贝叶斯)、聚类、降维 书籍资源-百度云盘下载提取码：4fi8 Kaggle大数据竞赛平台——Kaggle 入门 Kaggle 论文深入AI所有领域最优论文+代码查找神器：966个ML任务、8500+论文任你选-知乎 (上边链接是Paper with code的使用介绍) Paper with code]]></content>
      <categories>
        <category>机器学习</category>
        <category>教程</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>AI</tag>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
        <tag>Sklearn</tag>
        <tag>Mxnet</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[堪称神器的Chrome插件推荐]]></title>
    <url>%2F2019%2F03%2F26%2F%E5%A0%AA%E7%A7%B0%E7%A5%9E%E5%99%A8%E7%9A%84Chrome%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%90%2F</url>
    <content type="text"><![CDATA[注意: 没有翻墙的话是不能在Chrome里的Google网上商店下载插件的 ​ 没有翻墙可以去：https://www.chromefor.com/ 在此网站下载的是.CRX文件 ​ 如何安装离线Chrome插件?（.CRX文件） 1、OneTab当在Chrome中打开多个标签页的时候： 点击： 效果： Google商店下载 非官方网站下载 2、沙拉查词划词翻译插件 鼠标在单词上双击即可翻译 用鼠标选择一句话 右键“沙拉查词”图标，打开沙拉查词的设置 在设置这里打开划词翻译，更多设置请自己试试 Google商店下载 非官方网站 3、Adblock Plus拦截广告插件，几乎可以拦截所有广告，如果有些拦截不了，还可以添加黑名单 （知乎、CSDN、电影网站、小说网站……） Google商店下载 非官方网站 4、Infinity 新标签页(Pro)打开一个新的标签页 5、新浪微博图床 Google商店下载 非官方网站 Reference: 有哪些实用且堪称神器的Chrome插件？吐血推荐！！！]]></content>
      <categories>
        <category>实用</category>
        <category>非技术</category>
      </categories>
      <tags>
        <tag>Chrome</tag>
        <tag>插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SciKit-Learn教程]]></title>
    <url>%2F2019%2F03%2F26%2FLearn-sklearn%2F</url>
    <content type="text"><![CDATA[介绍Scikit-learn（简称sklearn）是开源的Python机器学习库，它基于Numpy和Scipy，提供了大量用于数据挖掘和分析的工具，包括数据预处理、交叉验证、算法与可视化算法等一系列接口。 sklearn的官方网站是http://scikit-learn.org/stable/，在上面可以找到相关的Scikit-Learn的资源，模块下载，文档，例程等。sklearn的基本功能主要被分为六个部分，分类，回归，聚类，数据降维，模型选择，数据预处理，具体可以参考官方网站上的文档。 Reference： Scikit-Learn简介 通用学习模式1、导入数据、模型 2、获取特征数据与对应标记 3、训练集/测试集划分（K折交叉验证） 4、模型训练 5、模型性能评估(predict、score) K近邻1、导入数据、模型 123from sklearn import datasetsfrom sklearn.model_selection import train_test_split # 划分训练集/测试集的模块from sklearn.neighbors import KNeighborsClassifier 2、获取特征数据与标记 123iris = datasets.load_iris()iris_X = iris.datairis_y = iris.target 3、训练集/测试集划分（随机打乱数据后按照给定参数划分训练集/测试集） 1X_train,X_test,y_train,y_test = train_test_split(iris_X,iris_y,test_size=0.3) 4、模型训练 12knn = KNeighborsClassifier()knn.fit(X_train,y_train) 5、模型性能评估(predict、score) 12print(knn.predict(X_test))print(y_test) 1234[0 2 1 2 0 2 1 0 1 2 2 1 0 0 1 2 1 0 2 2 2 1 2 1 0 2 1 2 0 0 0 2 1 2 0 1 0 0 2 2 0 2 2 0 1][0 2 1 1 0 2 1 0 1 2 2 1 0 0 1 2 1 0 2 2 2 1 2 1 0 2 1 2 0 0 0 1 1 2 0 1 0 0 2 2 0 2 2 0 1] 参数1knn.get_params # 获得之前模型设置的参数 &lt;bound method BaseEstimator.get_params of KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;, metric_params=None, n_jobs=1, n_neighbors=5, p=2, weights=&#39;uniform&#39;)&gt; 线性回归1、导入模块 12from sklearn import datasetsfrom sklearn.linear_model import LinearRegression 2、载入数据 123loaded_data = datasets.load_boston() # boston房价与一些特征数据data_X = loaded_data.data # 特征数据，即：面积、楼层、离市中心远近等等data_y = loaded_data.target # 房价 3、模型选择、模型训练 12model = LinearRegression() # 线性回归模型model.fit(data_X,data_y) 4、模型性能评估 123# 预测第0、1、2、3个样本的房价 单位:/万print(model.predict(data_X[:4,:])) print(data_y[:4]) [ 30.00821269 25.0298606 30.5702317 28.60814055] [ 24. 21.6 34.7 33.4] 模型的参数模型不同特征所对应的斜率: 1print(model.coef_) array([ -1.07170557e-01, 4.63952195e-02, 2.08602395e-02, 2.68856140e+00, -1.77957587e+01, 3.80475246e+00, 7.51061703e-04, -1.47575880e+00, 3.05655038e-01, -1.23293463e-02, -9.53463555e-01, 9.39251272e-03, -5.25466633e-01]) 模型的截距（与y轴的交点）: 1print(model.intercept_) 36.491103280361983 创造一些数据1import matplotlib.pyplot as plt 参数说明： make_regression()：生成一些适用于回归模型的样本 n_samples：生成的样本数 n_features：特征个数 n_targets：标记个数 noise：样本噪声，越大样本越离散 1X,y = datasets.make_regression(n_samples=100,n_features=1,n_targets=1,noise=5) 样本可视化 12plt.scatter(X,y)plt.show() 正规化 Normalization数据标准化12from sklearn import preprocessing #标准化数据模块import numpy as np 1234a = np.array([[10,2.7,3.6], [-100, 5, -2], [120, 20, 40] ],dtype = np.float64) 将Normalized前的a打印出来： 1print(a) 123[[ 10. 2.7 3.6] [-100. 5. -2. ] [ 120. 20. 40. ]] 将Normalized后的a打印出来： 1print(preprocessing.scale(a)) [[ 0. -0.85170713 -0.55138018] [-1.22474487 -0.55187146 -0.852133 ] [ 1.22474487 1.40357859 1.40351318]] 数据标准化对机器学习性能的影响1、模块导入 12345678910from sklearn import preprocessing#标准化数据模块import numpy as np# 划分训练集/测试集的模块from sklearn.model_selection import train_test_split # 生成适合做classification资料的模块from sklearn.datasets.samples_generator import make_classification# Support Vector Machine中的Support Vector Classifierfrom sklearn.svm import SVC# 可视化数据的模块import matplotlib.pyplot as plt 2、生成数据 12345X, y = make_classification( n_samples=300, n_features=2, n_redundant=0, n_informative=2, random_state=22, n_clusters_per_class=1, scale=100) 3、数据可视化 123#可视化数据plt.scatter(X[:, 0], X[:, 1], c=y)plt.show() 数据标准化前的模型准确率 1234X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)clf = SVC()clf.fit(X_train,y_train)print("数据标准化之前,准确率为：",clf.score(X_test,y_test)) 数据标准化之前,准确率为： 0.477777777778 数据标准化之后的模型准确率 123456X = preprocessing.scale(X) # NomalizationX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)clf = SVC()clf.fit(X_train, y_train)print("数据标准化之后,准确率为：",clf.score(X_test, y_test))# 0.9 数据标准化之后,准确率为： 0.977777777778 显而易见，数据标准化之后，模型的准确率有了巨大的提升 交叉验证Model 基础验证法12345# iris数据集from sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_split# K最近邻(kNN，k-NearestNeighbor)分类算法from sklearn.neighbors import KNeighborsClassifier 1234567891011121314151617#加载iris数据集iris = load_iris()X = iris.datay = iris.target#分割数据并X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4)#建立模型knn = KNeighborsClassifier()#训练模型knn.fit(X_train, y_train)#将准确率打印出print(knn.score(X_test, y_test))# 0.973684210526 0.973684210526 Model 交叉验证法(Cross Validation)将一个数据集，在每轮次训练前，划分成不同的Train_Set和Test_Set 使用K折交叉验证模块:scores = cross_val_score(knn, X, y, cv=5, scoring=’accuracy’) 参数说明： cross_val_score()：模型的交叉验证法，使模型性能评估更加精准，更加可靠 第一个参数：使用的算法模型 第二个参数：数据集 第三个参数：数据集所对应的标记 cv：k折交叉验证，的K值 scoring：使用什么方法来进行性能评分 ‘accuracy’(精确率)一般用于分类模型 ‘mean_squared_error’(平均方差)一般用于回归模型，使用此值函数输出会是负值，所以需要在函数前边加一个负号 12345678910from sklearn.cross_validation import cross_val_score # K折交叉验证模块#使用K折交叉验证模块scores = cross_val_score(knn, X, y, cv=5, scoring='accuracy')#将5次的预测准确率打印出print(scores)#将5次的预测准确平均率打印出print(scores.mean()) [ 0.96666667 1. 0.93333333 0.96666667 1. ] 0.973333333333 以准确率判断 ​ 一般来说准确率(accuracy)会用于判断分类(Classification)模型的好坏。 123456789101112131415161718import matplotlib.pyplot as plt #可视化模块#建立测试参数集k_range = range(1, 31)k_scores = []#藉由迭代的方式来计算不同参数对模型的影响，并返回交叉验证后的平均准确率for k in k_range: knn = KNeighborsClassifier(n_neighbors=k) scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy') k_scores.append(scores.mean())#可视化数据plt.plot(k_range, k_scores)plt.xlabel('Value of K for KNN')plt.ylabel('Cross-Validated Accuracy')plt.show() ​ 从图中可以得知，选择12~18的k值最好。高过18之后，准确率开始下降则是因为过拟合(Over fitting)的问题。 以平均方差(Mean squared error) ​ 一般来说平均方差(Mean squared error)会用于判断回归(Regression)模型的好坏。 123456789101112import matplotlib.pyplot as pltk_range = range(1, 31)k_scores = []for k in k_range: knn = KNeighborsClassifier(n_neighbors=k) loss = -cross_val_score(knn, X, y, cv=10, scoring='mean_squared_error') k_scores.append(loss.mean())plt.plot(k_range, k_scores)plt.xlabel('Value of K for KNN')plt.ylabel('Cross-Validated MSE')plt.show() 由图可以得知，平均方差越低越好，因此选择13~18左右的K值会最好。 Learning curve 检视过拟合参数说明： learning_curve()：模型的交叉验证法，使模型性能评估更加精准，更加可靠 第一个参数：算法模型 第二个参数：数据集 第三个参数：数据集所对应的标记 cv：k折交叉验证，的K值 scoring：使用什么方法来进行性能评分 ‘accuracy’(精确率)一般用于分类模型 ‘mean_squared_error’(平均方差)一般用于回归模型，使用此值函数输出会是负值，所以需要在函数前边加一个负号 train_sizes：元素取值为0-1的列表，表示第百分之几个样本记录一次 返回值：一个元组(p1,p2 ,p3 ) train_sizes（每次记录时，第几个样本正在训练）, train_loss（二维列表，每行对应train_sizes的一个元素，行中存储K次训练集交叉验证的误差记录， len(train_sizes) 行，K列） test_loss（二维列表，每行对应train_sizes的一个元素，行中存储K次测试集交叉验证的误差记录， len(train_sizes) 行，K列） 1、加载对应模块 12345from sklearn.learning_curve import learning_curve #学习曲线模块from sklearn.datasets import load_digits #digits数据集from sklearn.svm import SVC #Support Vector Classifierimport matplotlib.pyplot as plt #可视化模块import numpy as np 2、加载digits数据集，其包含的是手写体的数字，从0到9。数据集总共有1797个样本，每个样本由64个特征组成， 分别为其手写体对应的8×8像素表示，每个特征取值0~16。 123digits = load_digits()X = digits.datay = digits.target 3、设置观察样本由小到大的学习曲线变化参数, 采用K折交叉验证 cv=10, 选择平均方差检视模型效能 scoring=’mean_squared_error’, 样本由小到大分成5轮检视学习曲线(10%, 25%, 50%, 75%, 100%): 1234567train_sizes, train_loss, test_loss = learning_curve( SVC(gamma=0.01), X, y, cv=10, scoring='mean_squared_error', train_sizes=[0.1, 0.25, 0.5, 0.75, 1])#平均每一轮所得到的平均方差(共5轮，分别为样本10%、25%、50%、75%、100%)train_loss_mean = -np.mean(train_loss, axis=1)test_loss_mean = -np.mean(test_loss, axis=1) 4、可视化图形: 123456789plt.plot(train_sizes, train_loss_mean, 'o-', color="r", label="Training")plt.plot(train_sizes, test_loss_mean, 'o-', color="g", label="Cross-validation")plt.xlabel("Training examples")plt.ylabel("Loss")plt.legend(loc="best")plt.show() gamma = 0.001时： gamma = 0.01时： 很明显以gamma = 0.01的参数来训练模型时，模型出现了严重的Overfitting(过拟合)问题 validation_curve 检视过拟合​ 使用validation_curve验证SVC中的一个参数gamma,在什么范围内能使 model 产生好的结果。以及过拟合和 gamma取值的关系 1234567891011121314151617181920212223242526272829303132from sklearn.learning_curve import validation_curve #validation_curve模块from sklearn.datasets import load_digits from sklearn.svm import SVC import matplotlib.pyplot as plt import numpy as np#digits数据集digits = load_digits()X = digits.datay = digits.target#建立参数测试集param_range = np.logspace(-6, -2.3, 5)#使用validation_curve快速找出参数对模型的影响train_loss, test_loss = validation_curve( SVC(), X, y, param_name='gamma', param_range=param_range, cv=10, scoring='mean_squared_error')#平均每一轮的平均方差train_loss_mean = -np.mean(train_loss, axis=1)test_loss_mean = -np.mean(test_loss, axis=1)#可视化图形plt.plot(param_range, train_loss_mean, 'o-', color="r", label="Training")plt.plot(param_range, test_loss_mean, 'o-', color="g", label="Cross-validation")plt.xlabel("gamma")plt.ylabel("Loss")plt.legend(loc="best")plt.show() 由图中可以明显看到gamma值大于0.001，模型就会有过拟合(Overfitting)的问题。 保存模型首先简单建立与训练一个SVC Model。 1234567from sklearn import svmfrom sklearn import datasetsclf = svm.SVC()iris = datasets.load_iris()X, y = iris.data, iris.targetclf.fit(X,y) 使用pickle保存使用pickle来保存与读取训练好的Model 12345678910111213import pickle #pickle模块#保存Model(注:save文件夹要预先建立，否则会报错)with open('save/clf.pickle', 'wb') as f: pickle.dump(clf, f)#读取Modelwith open('save/clf.pickle', 'rb') as f: clf2 = pickle.load(f) #测试读取后的Model 预测类别 print(clf2.predict(X[0:1]))# [0] 使用保存joblib保存joblib是sklearn的外部模块。 123456789101112from sklearn.externals import joblib #jbolib模块#保存Model(注:save文件夹要预先建立，否则会报错)joblib.dump(clf, 'save/clf.pkl')#读取Modelclf3 = joblib.load('save/clf.pkl')#测试读取后的Model 准确率评估print(clf3.score(X,y))# 0.986666666667 joblib在使用上比较容易，读取速度也相对pickle快。 所以直接选择使用joblib即可。 Author：morvanzhou]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Sklearn</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神经网络技巧]]></title>
    <url>%2F2019%2F03%2F24%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[神经网络技巧1、检验神经网络Reference: 检验神经网络 (Evaluation) 2、特征标准化 (Feature Normalization)1、minmax normalization (0 , 1) 2、std normalization (mean = 0, std = 1) Reference: 特征标准化 (Feature Normalization) 3、选取好用的特征(Good Features)以分类问题为例 1、避免无用信息，即：对于区分类别不大的特征要忽略掉 2、避免选取重复的特征，如：距离：1公里 = 2里，这两个特征是具有同样的意义的 3、避免复杂的特征，如：描述距离，两个地点的经纬度(A: 10,98 B：25,97)可以算出距离，但是已经有了一个A、B间的距离：3KM，我们选取复杂度更小的 Reference: 3.3 选择好特征 (Good Features) 4、处理不均衡的数据不均衡的数据，预测多的那一方准确率就能达到很高，神经网络在学习时,也会变成“多数派” 1、想办法获取更多的数据，使得数据均衡 2、换个评判方式 ​ 原因：对于不均衡数据，Accuracy和Cost变得不在那么重要（为什么不重要了？） ​ 使用F1 score（or F-score)评判： ​ Confusion Matrix —-&gt; Precision &amp; Recall ——&gt; F1 Score(or F-score) 3、重组数据 砍掉多数部分的一些数据 对少数部分的数据进行复制和生成（具体怎么做？） 4、使用其他机器学习方法 ​ 如：决策树，不均衡类别的数据并不会对所生成的决策树的性能有所影响 ​ 原因：决策树的每一个非叶子节点都是样本的特征，只有叶子节点是分类，在最终分类之前决策树只利用到了样本的特征和特征值，在最终分类时 5、修改算法 ​ 例如：Sigmoid函数，在x = 0 时，f(0) = 0.5 当f(x) &gt; 0.5 时划分为正例 当f(x) &lt; 0.5 时划分为反例 我们可以适当的提升 f(x) &gt; ? 时的正反例划分，如：f(x) &gt; 0.8时划分为正例，f(x) &lt; 0.8时划分为反例 Reference: ​ 处理不均衡数据 (深度学习)! 5、激活函数(Activation Function)​ 使得线性不可分问题转化为一个非线性可分问题 Reference: ​ 激励函数 (Activation Function) 6、过拟合问题(Overfitting)模型在训练集性能上很好，在实际问题中性能很差 1、L1/L2/… regularization 2、dropout Reference: 过拟合 (Overfitting) 7、加速神经网络的训练 SGD Momentum AdaGrad RMSprop Adam Reference: 加速神经网络训练 (Speed Up Training) 8、批标准化（Batch Normalization）问题：输入层/隐藏层神经元的激活函数对于输入饱和 例如：对于Sigmoid函数，对于x &lt;= -5，x &gt;= 5的输入数据，神经元的输出变化值非常小(即：梯度会非常小)，激活函数对于过大过小的输入不敏感 我们可以说，输入数据的分布对于激活函数来说是很重要的 Reference: 批标准化 (Batch Normalization) 9、L1/L2 正规化（Regularization）Reference: L1 / L2 正规化 (Regularization) 神经网络的黑盒不黑​ 对于神经网络的每一层进行查看 ​ 特征(输入)——&gt;代表特征——&gt;更高级(抽象)的代表特征——&gt;…..——&gt;输出 ​ 其中： ​ ‘’——&gt;“: 表示神经网络的一层对于上一层的输出的处理 ​ 输入、输出是我们人类所能理解的 ​ 而神经网络中间层的特征抽象是人类很难以理解的,但是对于计算机来说很容易理解 Reference: ​ 科普: 神经网络的黑盒不黑 (深度理解神经网络) 神经网络的进化​ 基于遗传算法、进化策略使得神经网络得以‘’代代进化‘’，即：每代神经网络对于目标问题的解更优，或说泛化误差更低。 Reference: ​ [什么是神经网络进化? What is Neuro-Evolution?](]]></content>
      <categories>
        <category>机器学习</category>
        <category>神经网络</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo搭建个人博客教程]]></title>
    <url>%2F2019%2F03%2F17%2FHexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Hexo搭建个人博客教程Hexo简介Hexo是一款基于Node.js的静态博客框架，依赖少易于安装使用，可以方便的生成静态网页托管在GitHub和Coding上，是搭建博客的首选框架。大家可以进入hexo官网进行详细查看，因为Hexo的创建者是台湾人，对中文的支持很友好，可以选择中文进行查看。 系统环境 系统：Linux 教程分为四个部分第一部分：Hexo-在本地创建博客 第二部分：部署到Github 第三部分：写博客 第四部分：使用Next主题—博客外观美化、功能拓展 第一部分：Hexo-在本地创建博客 1、安装Git2、安装Node.js3、安装Hexo4、开始使用Hexo 一、在Linux上安装Git12sudo apt-get install gitgit --version //查看git的版本,验证是否安装成功 二、安装Node.js123//安装node.jssudo apt-get install nodejssudo apt-get install npm 123//查看版本,验证是否安装成功node -vnpm -v 三、安装Hexo1、安装Hexo1npm install -g hexo-cli 2、查看Hexo版本号,验证是否安装成功1hexo -v 四、开始使用Hexo1、在当前目录下初始化一个Hexo工程 hexo init myblog 注: myblog是Hexo工程的名称,可以按照自己的想法随意取 2、进入myblog文件夹 cd myblog npm install 新建完成后，指定文件夹目录下有：node_modules: 依赖包public：存放生成的页面 (使用hexo g 命令后生成的静态网页文件存放的位置)scaffolds：生成文章的一些模板source：用来存放你的文章themes：主题_config.yml: Hexo博客工程的配置文件 3、生成静态网页文件 hexo g(完整命令： hexo generate) 1*注:该命令必须在**Hexo工程目录**下使用,生成的静态文件保存在**myblog工程**下,的**public文件夹**里* 4、打开Hexo服务 hexo s(完整命令： hexo server) 在浏览器输入localhost:4000就可以看到你生成的博客了 第二部分：部署到Github一、注册Github账户Github注册链接 如果有了就不需要注册了 二、登录Github,并创建仓库1、登录2、创建仓库:JKingKong.github.io 点击“New” 仓库名： 你的Github用户名.github.io 注：JKingKong——-&gt;你的Github的用户名 3、生成SSH公钥​ 为什么需要生成SSH公钥？ ​ 大多数 Git 服务器都会选择使用 SSH 公钥来进行授权。系统中的每个用户都必须提供一个公钥用于授权，没有的话就要生成一个。 ​ 1、SSH 公钥默认储存在账户的主目录下的 ~/.ssh 目录。进去看看： 1234$ cd ~/.ssh$ ls显示结果：authorized_keys id_rsa id_rsa.pub known_hosts 关键是看有没有用 something 和 something.pub 来命名的一对文件，这个 something 通常就是 id_dsa 或 id_rsa。有 .pub 后缀的文件就是公钥，另一个文件则是私钥。假如没有这些文件，或者干脆连 .ssh 目录都没有，可以用 ssh-keygen 来创建。该程序在 Linux/Mac 系统上由 SSH 包提供 ​ 2、生成SSH公钥与私钥 123456781、$ git config --global user.name "yourname"$ git config --global user.email "youremail"2、可以用以下两条，检查一下你有没有输对$ git config user.name$ git config user.email3、创建公钥与私钥,并且一路回车$ ssh-keygen -t rsa -C "youremail" ​ 3、查看SSH公钥 123456789$ cat ~/.ssh/id_rsa.pub输出：ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSUGPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlELEVf4h9lFX5QVkbPppSwg0cda3Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XAt3FaoJoAsncM1Q9x5+3V0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/EnmZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbxNrRFi9wrf+M7Q== schacon@agadorlaptop.local//复制上边的全部输出(你自己电脑上运行命令的全部输出结果,不是这个) 最后说一下SSH： ​ SSH，简单来讲，就是一个秘钥，其中，id_rsa是你这台电脑的私人秘钥，不能给别人看的，id_rsa.pub是公共秘钥，可以随便给别人看。把这个公钥放在GitHub上，这样当你链接GitHub自己的账户时，它就会根据公钥匹配你的私钥，当能够相互匹配时，才能够顺利的通过Git上传你的文件到GitHub上。 More: GitHub 上有关 SSH 公钥的向导 4、在Github上添加公钥 Key框里粘贴上边查看SSH公钥部分所复制的东西,而后点击“Add SSH key”,即可完成添加公钥步骤 使用该命令确认是否成功： 1$ ssh -T git@github.com 5、将Hexo部署到Github这一步，我们就可以将Hexo和GitHub关联起来，也就是将Hexo生成的静态网站部署到GitHub上 1、打开myblog工程下的站点配置文件 _config.yml，翻到最后，修改 1234deploy: type: git repo: git@github.com:你的Github用户名/你的Github用户名.github.io.git branch: master 保存修改。 2、安装deploy-git 1$ npm install hexo-deployer-git --save 6、部署1、在myblog工程下运行,以下命令12345678//清除缓存文件 (db.json) 和已生成的静态文件 (public)。//在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。$ hexo clean//在myblog工程的public文件夹下生成静态文件$ hexo generate//hexo的部署命令,按照_config.yml文件里的deploy配置部署,git部署需要安装hexo-deployer-git（上边装了）,会将public文件夹下的文件部署到'你的Github用户名.github.io'仓库下$ hexo deploy（hexo d -g //第二、第三条命令同时执行） 部署完成 2、访问你的静态博客网站https://你的Github用户名.github.io (记住一定要使用https) 第三部分：写博客Reference: Hexo系列教程第三期 写作 第四部分：使用Next主题—博客外观美化、功能拓展1、从Github克隆(下载)Next主题 git clone https://github.com/theme-next/hexo-theme-next themes/next 此命令的解释: 从Github上克隆Next主题到myblog工程下的themes文件夹下,并把主题命名为：next 2、在myblog工程下找到_config.yml文件_config.yml文件(博客工程的配置文件) 3、打开_config.yml文件 vim _config.yml 注：可以使用vim命令打开,也可以用VS Code、记事本、任意文本编辑器打开 4、修改配置文件,使用next主题 找到theme项,改成theme: next 而后保存 5、重新hexo g, hexo s 在浏览器输入localhost:4000,查看效果 注: 1、‘:’后边必须有空格,yml语言格式要求 2、next是myblog工程下theme文件夹里的next文件夹,即:上边从Github克隆的Next主题 Next主题配置参考：(下边的教程可能使用Next版本比最新版的低一些,有些地方的配置会有不同) Next主题的配置-视频(强烈推荐看一下) Next中文使用文档-开始使用 Next中文使用文档-主题配置 Next中文使用文档-第三方服务集成 此篇博客参考： Hexo中文文档 Hexo系列教程 hexo超完整的搭建教程，让你拥有一个专属个人博客 Next主题的配置-视频 Next中文使用文档 More: 关于博客多端同步思路： 1、JKingKong.github.io仓库下 master分支保存静态网页文件 2、JKingKong.github.io仓库下 hexo分支下保存Hexo工程文件(上边的myblog文件) 3、在其它电脑使用时先克隆Hexo分支下保存Hexo工程文件,修改后生成好静态网页文件,而后推送到master分支,并且将修改好的克隆文件推送到Hexo分支]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>博客</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F03%2F16%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
