<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2019%2F04%2F01%2F%E7%B2%BE%E7%A1%AE%E5%BA%A6%EF%BC%88Precision%EF%BC%89%E3%80%81%E5%8F%AC%E5%9B%9E%E7%8E%87%EF%BC%88Recall%EF%BC%89%E3%80%81F%E5%80%BC%EF%BC%88F-Measure%EF%BC%89%2F</url>
    <content type="text"><![CDATA[准确率（Accuracy）、精确度（Precision）、召回率（Recall）、F值（F-Measure）、RoC曲线、PR曲线1、TP、FP、TN、FN True Positives，TP：预测为正样本，实际也为正样本的特征数 False Positives，FP：预测为正样本，实际为负样本的特征数 True Negatives，TN：预测为负样本，实际也为负样本的特征数 False Negatives，FN：预测为负样本，实际为正样本的特征数 2、准确率（Accuracy）​ 准确率（Accuracy）是模型预测正例、反例对的数量所占总样本数的比例$$A = \frac{TP + TN}{TP + FP +TN + FN}$$亦即：$$准确率 = \frac{预测对的数量}{总样本数量}$$ 3、精确度（Precision）​ 精确度（Precision）是针对我们的预测结果而言的，它表示的是预测为正的样本中有多少是真正的正样本。 预测为正有两种可能： 把样本正类预测为正类（TP） 把样本负类预测为正类（FP） $$P = \frac{TP}{TP + FP}$$ 4、召回率（Recall）​ 召回率（Recall）是针对原来的样本而言的，它表示样本中的正例有多少被预测正确了 预测有两种可能： 把样本正类预测成正类（TP） 把样本正类预测为负类（FN） $$R = \frac{TP}{TP + FN}$$ 5、F-SCORE​ 有些时候单一的精确度（Precision）和召回率（Recall）高并不能很好的反映模型的真实性能。我们一般希望Precision和Recall尽可能都高。 所以F-SCORE(或称F-Measure):$$F = \frac{P R 2}{P + R}$$or$$\frac{2}{F} = \frac{1}{P} + \frac{1}{Q}$$ 6、例子​ 原始样本：60个是好瓜，40个是坏瓜，总数：100。 ​ 你训练了一个选西瓜的模型。你的模型挑选出85个瓜。里边真实标记有50个好瓜，35个坏瓜。 TP（将好瓜预测成好瓜）：40 FP（将坏瓜预测成好瓜）：15 TN（将坏瓜预测成坏瓜）：20 FN（将好瓜预测成坏瓜）：10 $$A = \frac{TP+TN}{TP+FP+TN+FN} = \frac{40+20}{85}= 70\%$$ $$P =\frac{TP}{TP+FP} =\frac{40}{40 + 15} = 72.7272\%$$ $$R = \frac{TP}{TP+FN}=\frac{40}{40 + 10} = 50\%$$ $$F = \frac{P R 2}{P + R} = \frac{0.72720.52}{0.7272+0.5} = 59.25\%$$ 看一张图： 7、灵敏度(true positive rate ,TPR)和特异度(false positive rate, FPR)​ 灵敏度(true positive rate ,TPR)，它是所有实际正例中，正确识别的正例比例，它和召回率的表达式没有区别。$$TPR = \frac{TP}{TP+FN}$$​ 特异度(false positive rate, FPR)，它是实际负例中，错误得识别为正例的负例比例。$$FPR = \frac{FP}{FP+FN}$$ 8、RoC曲线和PR曲线​ RoC曲线：以TPR为**y轴，以FPR为x轴**。 ​ 从FPR和TPR的定义可以理解，TPR越高，FPR越小，我们的模型和算法就越高效。也就是画出来的RoC曲线越靠近左上越好。从几何的角度讲，RoC曲线下方的面积越大越大，则模型越优。所以有时候我们用RoC曲线下的面积，即AUC（Area Under Curve）值来作为算法和模型好坏的标准。 PR曲线：以Precision为y轴，以Recall为x轴 ​ 仍然从精确率和召回率的定义可以理解，精确率越高，召回率越高，我们的模型和算法就越高效。也就是画出来的PR曲线越靠近右上越好。如上图右图所示。 使用RoC曲线和PR曲线，我们就能很方便的评估我们的模型的分类能力的优劣了。 Reference： [精确率与召回率，RoC曲线与PR曲线] 如何解释召回率与准确率？ 推荐系统评测指标—准确率(Precision)、召回率(Recall)、F值(F-Measure)]]></content>
  </entry>
  <entry>
    <title><![CDATA[MarkDown使用教程]]></title>
    <url>%2F2019%2F03%2F26%2FMarkDown%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[MarkDown使用教程介绍Markdown是一种轻量级标记语言，创始人为约翰·格鲁伯（英语：John Gruber）。它允许人们“使用易读易写的纯文本格式编写文档，然后转换成有效的XHTML（或者HTML）文档”。[4]这种语言吸收了很多在电子邮件中已有的纯文本标记的特性。 由于Markdown的轻量化、易读易写特性，并且对于图片，图表、数学式都有支持，当前许多网站都广泛使用 Markdown 来撰写帮助文档或是用于论坛上发表消息。例如：GitHub、reddit、Diaspora、Stack Exchange、OpenStreetMap 、SourceForge等。甚至Markdown能被使用来撰写电子书。 MarkDown基础语法Reference: MarkDown基础语法 请结合下边的在线编辑器实际写一下，并且查看效果 MarkDown在线编辑阅读器Cmd Markdown 编辑阅读器 MarkDown本地编辑器推荐：Typora (windows) 12 款 Markdown 写作工具推荐]]></content>
      <categories>
        <category>MarkDown</category>
        <category>教程</category>
      </categories>
      <tags>
        <tag>MarkDown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强化学习方法汇总]]></title>
    <url>%2F2019%2F03%2F26%2F%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[强化学习方法汇总​ 是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。其灵感来源于心理学中的行为主义理论，即有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能获得最大利益的习惯性行为。 Reference: 强化学习- 维基百科 不同的划分方式一、不理解环境(Model-Free RL) 和理解环境（Model-Based RL)不理解环境(Model-Free RL) ：​ 直接对环境作出动作，而后接收来自于环境的反馈，对于周围的环境是不理解的，没有概念的，作出动作后只能等待现实的反馈，是否这个动作的反馈会造成好的还是坏的结果，它也是没有概念的、不知道的。 例如：我们在现实世界投放一颗氢弹，然后我们成功把自己玩死了，这是一个很坏的结果，但我们事先对此没有概念，不知道做出这个“投放氢弹”会发生什么，我们只能去尝试一下，然后Die。 方法： Q learning Sarsa Policy Gradients learning 理解环境（Model-Based RL):​ 1、机器人会通过过往的经验，先理解真实世界是怎样的 ​ 2、建立一个模型来模拟现实世界的反馈(建立一个模拟现实) ​ 3、既可以在现实世界中作出动作，也可以在模拟世界中作出动作 这样就没必要去炸真实世界，连自己也炸死了，他可以像玩游戏一样炸炸游戏里的世界，也保住了自己的小命 进一步说明： ​ 基于Model-Based RL的机器人能通过想象来预判断接下来将要发生的所有情况。然后选择这些想象情况中最好的那种。并依据这种情况来采取下一步的策略。 方法： ​ 1、先在Model-Free RL的基础上添加了一层对于现实世界的建模(一个虚拟的世界) ​ 2、然后在这个模拟世界里进行Model-Free RL ( Q learning、Sarsa、Policy Gradients) 二、基于概率(Policy-Based RL) 和基于价值（Value-Based RL)基于概率(Policy-Based RL) :​ 机器人能通过感官分析所处的环境，直接输出下一步要采取的各种动作的概率，然后根据概率采取行动，所以每种动作都有可能被选中， 只是可能性不同，即使是大概率的动作也不一定会选到。 方法： Policy Gradients learning …. 基于价值（Value-Based RL):​ 在当前这一步，输出所有可能采取的动作(不连续的动作)的价值，我们会根据最高价值来选着动作，这种决策十分确定，只选取价值最高的 方法： Q learning Sarsa …. 基于概率与价值的结合创造了一种更好的方法： Actor-Critic ( 1、Actor ：基于概率做出一个动作 2、Critic 会对做出的动作给出动作的价值，这样就在原有的 policy gradients 上加速了学习过程) 对于连续动作： ​ Value-Based是无能为力的 ( 为什么会说无能为力？？？) ​ Policy-Based能用一个概率分布在连续动作中选取特定动作，是Policy-Based的优点之一 三、回合更新(Monte-Carlo update RL) 和单步更新（Temporal-Difference update)想象强化学习就是在玩游戏, 游戏回合有开始和结束 回合更新(Monte-Carlo update RL) ：​ 指的是游戏开始后, 我们要等待游戏结束, 然后再总结这一回合中的所有转折点, 再更新我们的行为准则 方法： Monte-carlo learning 基础版的Policy learning …. 单步更新（Temporal-Difference update)：​ 在游戏进行中每一步都在更新, 不用等待游戏的结束, 这样我们就能边玩边学习了 方法： Q learning Sarsa 升级版Policy Gradients learning … 现在大多数学习都是Temporal-Difference update （因为有的强化学习问题并不属于回合问题，且单步更新训练速度快） 四、在线学习(On-Policy) 和离线学习（Off-Policy)在线学习(On-Policy) :​ 指必须本人在场, 并且一定是本人边玩边学习 方法： Sarsa Sarsa lambda ( 优化Sarsa算法) 离线学习（Off-Policy):特点： 可以选择自己玩 也可以选择看着别人玩，通过看别人玩，来学习别人的行为准则 同样是从过往的经验中学习, 但是这些过往的经历没必要是自己的经历, 任何人的经历都能被学习 或者我也不必要边玩边学习, 我可以白天先存储下来玩耍时的记忆, 然后晚上通过离线学习来学习白天的记忆 方法： Q learning Deep-Q-Network (更加强大的算法，可以让计算机学会玩电动) Reference: 强化学习方法汇总 (Reinforcement Learning)]]></content>
      <categories>
        <category>机器学习</category>
        <category>神经网络</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习、深度学习入门教程]]></title>
    <url>%2F2019%2F03%2F26%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%81%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[教程推荐介绍取自了解机器学习方法 (*可跳) 1.1 机器学习 (Machine Learning) 2.1 科普: 人工神经网络 VS 生物神经网络 2.2 神经网络 (Neural Network) 视频莫凡Python-机器学习（强烈推荐！！！） （强烈推荐！！！通俗易懂，能建立对于机器学习的大致认知，能对大致算法、应用有所了解，不在惧怕 缺点：理论方面不够深入，有志以后进行机器学习相关工作的可以阅读书籍或论文补足理论） 推荐学习顺序： 在机器学习前 - (零基础) Python基础语法 了解数据结构 (Numpy &amp; Pandas) 学会展示数据 (Matplotlib) 了解机器学习方法 (*可跳) 神经网络 Tensorflow (Google开发, 社区大) PyTorch (Facebook开发, 方便debug) Keras (类似Tensorflow, 推荐直接学Tensorflow) Theano (类似Tensorflow, 推荐直接学Tensorflow) 有监督/无监督/半监督/降维多功能包 (Sklearn) 机器人无师自通 (强化学习) 使用进化论的机器学习 (进化算法) 效率工具 代码管理维护 (Git) 远程/云端计算 (Linux基础) 网页爬虫 实战 从头做一个机器人手臂 从头做一个汽车状态分类器 吴恩达网易公开课-深度学习 （英语，但有中文字幕，缺点：缺少了一些课后练习，可以搜索引擎搜索 吴恩达深度学习 课后练习） 书籍1、深度学习 《动手学深度学习》 推荐！！！ 理论与实践并重, 有Kaggle(请看下边的介绍)的练习， 美中不足的是使用的是Mxnet框架，而不是TensorFlow 内容和结构： 本书内容大体可以分为3个部分： 第一部分（第1章至第3章）涵盖预备工作和基础知识。第1章介绍深度学习的背景。第2章提供动手学深度学习所需要的预备知识，例如，如何获取并运行本书中的代码。第3章包括深度学习最基础的概念和技术，如多层感知机和模型正则化。如果读者时间有限，并且只想了解深度学习最基础的概念和技术，那么只需阅读第一部分。 第二部分（第4章至第6章）关注现代深度学习技术。第4章描述深度学习计算的各个重要组成部分，并为实现后续更复杂的模型打下基础。第5章解释近年来令深度学习在计算机视觉领域大获成功的卷积神经网络。第6章阐述近年来常用于处理序列数据的循环神经网络。阅读第二部分有助于掌握现代深度学习技术。 第三部分（第7章至第10章）讨论计算性能和应用。第7章评价各种用来训练深度学习模型的优化算法。第8章检验影响深度学习计算性能的几个重要因素。第9章和第10章分别列举深度学习在计算机视觉和自然语言处理中的重要应用。这部分内容读者可根据兴趣选择阅读。 《神经⽹络与深度学习Neural Networks and Deep Learning》 （讲神经网络的，推荐全看！！！）（美）Michael Nielsen 著Xiaohu Zhu 译Freeman Zhang （内含有反向传播算法的证明，这算法真的很重要） 《解析卷积神经网络(深度学习实践手册)》 （讲卷积神经网络（CNN）的，可以先看《动手学深度学习》的卷积神经网络） 2、机器学习PS：需要高等数学（积分、求导、求梯度、求极值）、线性代数（基本矩阵运算、矩阵求导）、概率论（随机变量、分布、多维随机变量极其分布、期望、贝叶斯公式、极大似然估计），可以先看看书里的大致知识，看不懂再回去补充、回忆 ​ 《机器学习》 周志华 ​ 《统计学习方法》 李航 这两本可以对照着看，如果哪一本难以理解就看另一本或者结合网上的博客 推荐阅读：线性模型（线性回归、对率回归、LDA）、决策树（多变量决策树了解一下即可）、支持向量机、贝叶斯分类(朴素贝叶斯、半朴素贝叶斯)、聚类、降维 书籍资源-百度云盘下载提取码：4fi8 Kaggle大数据竞赛平台——Kaggle 入门 Kaggle 论文深入AI所有领域最优论文+代码查找神器：966个ML任务、8500+论文任你选-知乎 (上边链接是Paper with code的使用介绍) Paper with code]]></content>
      <categories>
        <category>机器学习</category>
        <category>教程</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>AI</tag>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
        <tag>Sklearn</tag>
        <tag>Mxnet</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[堪称神器的Chrome插件推荐]]></title>
    <url>%2F2019%2F03%2F26%2F%E5%A0%AA%E7%A7%B0%E7%A5%9E%E5%99%A8%E7%9A%84Chrome%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%90%2F</url>
    <content type="text"><![CDATA[注意: 没有翻墙的话是不能在Chrome里的Google网上商店下载插件的 ​ 没有翻墙可以去：https://www.chromefor.com/ 在此网站下载的是.CRX文件 ​ 如何安装离线Chrome插件?（.CRX文件） 1、OneTab当在Chrome中打开多个标签页的时候： 点击： 效果： Google商店下载 非官方网站下载 2、ChaZD划词翻译插件 鼠标在单词上双击即可翻译 用鼠标选择一句话 Google商店下载 非官方网站 3、Adblock Plus拦截广告插件，几乎可以拦截所有广告，如果有些拦截不了，还可以添加黑名单 （知乎、CSDN、电影网站、小说网站……） Google商店下载 非官方网站 4、Infinity 新标签页(Pro)打开一个新的标签页 5、新浪微博图床 Google商店下载 非官方网站 Reference: 有哪些实用且堪称神器的Chrome插件？吐血推荐！！！]]></content>
      <categories>
        <category>实用</category>
        <category>非技术</category>
      </categories>
      <tags>
        <tag>Chrome</tag>
        <tag>插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神经网络技巧]]></title>
    <url>%2F2019%2F03%2F24%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[神经网络技巧1、检验神经网络Reference: 检验神经网络 (Evaluation) 2、特征标准化 (Feature Normalization)1、minmax normalization (0 , 1) 2、std normalization (mean = 0, std = 1) Reference: 特征标准化 (Feature Normalization) 3、选取好用的特征(Good Features)以分类问题为例 1、避免无用信息，即：对于区分类别不大的特征要忽略掉 2、避免选取重复的特征，如：距离：1公里 = 2里，这两个特征是具有同样的意义的 3、避免复杂的特征，如：描述距离，两个地点的经纬度(A: 10,98 B：25,97)可以算出距离，但是已经有了一个A、B间的距离：3KM，我们选取复杂度更小的 Reference: 3.3 选择好特征 (Good Features) 4、处理不均衡的数据不均衡的数据，预测多的那一方准确率就能达到很高，神经网络在学习时,也会变成“多数派” 1、想办法获取更多的数据，使得数据均衡 2、换个评判方式 ​ 原因：对于不均衡数据，Accuracy和Cost变得不在那么重要（为什么不重要了？） ​ 使用F1 score（or F-score)评判： ​ Confusion Matrix —&gt; Precision &amp; Recall —-&gt; F1 Score(or F-score) 3、重组数据 砍掉多数部分的一些数据 对少数部分的数据进行复制和生成（具体怎么做？） 4、使用其他机器学习方法 ​ 如：决策树，不均衡类别的数据并不会对所生成的决策树的性能有所影响 ​ 原因：决策树的每一个非叶子节点都是样本的特征，只有叶子节点是分类，在最终分类之前决策树只利用到了样本的特征和特征值，在最终分类时 5、修改算法 ​ 例如：Sigmoid函数，在x = 0 时，f(0) = 0.5 当f(x) &gt; 0.5 时划分为正例 当f(x) &lt; 0.5 时划分为反例 我们可以适当的提升 f(x) &gt; ? 时的正反例划分，如：f(x) &gt; 0.8时划分为正例，f(x) &lt; 0.8时划分为反例 Reference: ​ 处理不均衡数据 (深度学习)! 5、激活函数(Activation Function)​ 使得线性不可分问题转化为一个非线性可分问题 Reference: ​ 激励函数 (Activation Function) 6、过拟合问题(Overfitting)模型在训练集性能上很好，在实际问题中性能很差 1、L1/L2/… regularization 2、dropout Reference: 过拟合 (Overfitting) 7、加速神经网络的训练 SGD Momentum AdaGrad RMSprop Adam Reference: 加速神经网络训练 (Speed Up Training) 8、批标准化（Batch Normalization）问题：输入层/隐藏层神经元的激活函数对于输入饱和 例如：对于Sigmoid函数，对于x &lt;= -5，x &gt;= 5的输入数据，神经元的输出变化值非常小(即：梯度会非常小)，激活函数对于过大过小的输入不敏感 我们可以说，输入数据的分布对于激活函数来说是很重要的 Reference: 批标准化 (Batch Normalization) 9、L1/L2 正规化（Regularization）Reference: L1 / L2 正规化 (Regularization) 神经网络的黑盒不黑​ 对于神经网络的每一层进行查看 ​ 特征(输入)—-&gt;代表特征—-&gt;更高级(抽象)的代表特征—-&gt;…..—-&gt;输出 ​ 其中： ​ ‘’—-&gt;“: 表示神经网络的一层对于上一层的输出的处理 ​ 输入、输出是我们人类所能理解的 ​ 而神经网络中间层的特征抽象是人类很难以理解的,但是对于计算机来说很容易理解 Reference: ​ 科普: 神经网络的黑盒不黑 (深度理解神经网络) 神经网络的进化​ 基于遗传算法、进化策略使得神经网络得以‘’代代进化‘’，即：每代神经网络对于目标问题的解更优，或说泛化误差更低。 Reference: ​ [什么是神经网络进化? What is Neuro-Evolution?](]]></content>
      <categories>
        <category>机器学习</category>
        <category>神经网络</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo搭建个人博客教程]]></title>
    <url>%2F2019%2F03%2F17%2FHexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Hexo搭建个人博客教程Hexo简介Hexo是一款基于Node.js的静态博客框架，依赖少易于安装使用，可以方便的生成静态网页托管在GitHub和Coding上，是搭建博客的首选框架。大家可以进入hexo官网进行详细查看，因为Hexo的创建者是台湾人，对中文的支持很友好，可以选择中文进行查看。 系统环境 系统：Linux 教程分为四个部分第一部分：Hexo-在本地创建博客 第二部分：部署到Github 第三部分：写博客 第四部分：使用Next主题–博客外观美化、功能拓展 第一部分：Hexo-在本地创建博客 1、安装Git2、安装Node.js3、安装Hexo4、开始使用Hexo 一、在Linux上安装Git12sudo apt-get install gitgit --version //查看git的版本,验证是否安装成功 二、安装Node.js123//安装node.jssudo apt-get install nodejssudo apt-get install npm 123//查看版本,验证是否安装成功node -vnpm -v 三、安装Hexo1、安装Hexo1npm install -g hexo-cli 2、查看Hexo版本号,验证是否安装成功1hexo -v 四、开始使用Hexo1、在当前目录下初始化一个Hexo工程 hexo init myblog 注: myblog是Hexo工程的名称,可以按照自己的想法随意取 2、进入myblog文件夹 cd myblog npm install 新建完成后，指定文件夹目录下有：node_modules: 依赖包public：存放生成的页面 (使用hexo g 命令后生成的静态网页文件存放的位置)scaffolds：生成文章的一些模板source：用来存放你的文章themes：主题_config.yml: Hexo博客工程的配置文件 3、生成静态网页文件 hexo g(完整命令： hexo generate) 1*注:该命令必须在**Hexo工程目录**下使用,生成的静态文件保存在**myblog工程**下,的**public文件夹**里* 4、打开Hexo服务 hexo s(完整命令： hexo server) 在浏览器输入localhost:4000就可以看到你生成的博客了 第二部分：部署到Github一、注册Github账户Github注册链接 如果有了就不需要注册了 二、登录Github,并创建仓库1、登录2、创建仓库:JKingKong.github.io 点击“New” 仓库名： 你的Github用户名.github.io 注：JKingKong—–&gt;你的Github的用户名 3、生成SSH公钥​ 为什么需要生成SSH公钥？ ​ 大多数 Git 服务器都会选择使用 SSH 公钥来进行授权。系统中的每个用户都必须提供一个公钥用于授权，没有的话就要生成一个。 ​ 1、SSH 公钥默认储存在账户的主目录下的 ~/.ssh 目录。进去看看： 1234$ cd ~/.ssh$ ls显示结果：authorized_keys id_rsa id_rsa.pub known_hosts 关键是看有没有用 something 和 something.pub 来命名的一对文件，这个 something 通常就是 id_dsa 或 id_rsa。有 .pub 后缀的文件就是公钥，另一个文件则是私钥。假如没有这些文件，或者干脆连 .ssh 目录都没有，可以用 ssh-keygen 来创建。该程序在 Linux/Mac 系统上由 SSH 包提供 ​ 2、生成SSH公钥与私钥 123456781、$ git config --global user.name "yourname"$ git config --global user.email "youremail"2、可以用以下两条，检查一下你有没有输对$ git config user.name$ git config user.email3、创建公钥与私钥,并且一路回车$ ssh-keygen -t rsa -C "youremail" ​ 3、查看SSH公钥 123456789$ cat ~/.ssh/id_rsa.pub输出：ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSUGPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlELEVf4h9lFX5QVkbPppSwg0cda3Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XAt3FaoJoAsncM1Q9x5+3V0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/EnmZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbxNrRFi9wrf+M7Q== schacon@agadorlaptop.local//复制上边的全部输出(你自己电脑上运行命令的全部输出结果,不是这个) 最后说一下SSH： ​ SSH，简单来讲，就是一个秘钥，其中，id_rsa是你这台电脑的私人秘钥，不能给别人看的，id_rsa.pub是公共秘钥，可以随便给别人看。把这个公钥放在GitHub上，这样当你链接GitHub自己的账户时，它就会根据公钥匹配你的私钥，当能够相互匹配时，才能够顺利的通过Git上传你的文件到GitHub上。 More: GitHub 上有关 SSH 公钥的向导 4、在Github上添加公钥 Key框里粘贴上边查看SSH公钥部分所复制的东西,而后点击“Add SSH key”,即可完成添加公钥步骤 使用该命令确认是否成功： 1$ ssh -T git@github.com 5、将Hexo部署到Github这一步，我们就可以将Hexo和GitHub关联起来，也就是将Hexo生成的静态网站部署到GitHub上 1、打开myblog工程下的站点配置文件 _config.yml，翻到最后，修改 1234deploy: type: git repo: git@github.com:你的Github用户名/你的Github用户名.github.io.git branch: master 保存修改。 2、安装deploy-git 1$ npm install hexo-deployer-git --save 6、部署1、在myblog工程下运行,以下命令12345678//清除缓存文件 (db.json) 和已生成的静态文件 (public)。//在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。$ hexo clean//在myblog工程的public文件夹下生成静态文件$ hexo generate//hexo的部署命令,按照_config.yml文件里的deploy配置部署,git部署需要安装hexo-deployer-git（上边装了）,会将public文件夹下的文件部署到'你的Github用户名.github.io'仓库下$ hexo deploy（hexo d -g //第二、第三条命令同时执行） 部署完成 2、访问你的静态博客网站https://你的Github用户名.github.io (记住一定要使用https) 第三部分：写博客Reference: Hexo系列教程第三期 写作 第四部分：使用Next主题–博客外观美化、功能拓展1、从Github克隆(下载)Next主题 git clone https://github.com/theme-next/hexo-theme-next themes/next 此命令的解释: 从Github上克隆Next主题到myblog工程下的themes文件夹下,并把主题命名为：next 2、在myblog工程下找到_config.yml文件_config.yml文件(博客工程的配置文件) 3、打开_config.yml文件 vim _config.yml 注：可以使用vim命令打开,也可以用VS Code、记事本、任意文本编辑器打开 4、修改配置文件,使用next主题 找到theme项,改成theme: next 而后保存 5、重新hexo g, hexo s 在浏览器输入localhost:4000,查看效果 注: 1、‘:’后边必须有空格,yml语言格式要求 2、next是myblog工程下theme文件夹里的next文件夹,即:上边从Github克隆的Next主题 Next主题配置参考：(下边的教程可能使用Next版本比最新版的低一些,有些地方的配置会有不同) Next主题的配置-视频(强烈推荐看一下) Next中文使用文档-开始使用 Next中文使用文档-主题配置 Next中文使用文档-第三方服务集成 此篇博客参考： Hexo中文文档 Hexo系列教程 hexo超完整的搭建教程，让你拥有一个专属个人博客 Next主题的配置-视频 Next中文使用文档 More: 关于博客多端同步思路： 1、JKingKong.github.io仓库下 master分支保存静态网页文件 2、JKingKong.github.io仓库下 hexo分支下保存Hexo工程文件(上边的myblog文件) 3、在其它电脑使用时先克隆Hexo分支下保存Hexo工程文件,修改后生成好静态网页文件,而后推送到master分支,并且将修改好的克隆文件推送到Hexo分支]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>Hexo</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F03%2F16%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
